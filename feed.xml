<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://minsuan96.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://minsuan96.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-26T04:03:45+00:00</updated><id>https://minsuan96.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">A Little Warm Up Before Mahjong RL</title><link href="https://minsuan96.github.io/blog/2024/gradient-descent/" rel="alternate" type="text/html" title="A Little Warm Up Before Mahjong RL"/><published>2024-02-22T00:00:00+00:00</published><updated>2024-02-22T00:00:00+00:00</updated><id>https://minsuan96.github.io/blog/2024/gradient-descent</id><content type="html" xml:base="https://minsuan96.github.io/blog/2024/gradient-descent/"><![CDATA[<p>Before delving directly into the algorithm, let me provide a brief explanation of what <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a> entails. Gradient descent is an optimization algorithm commonly used in machine learning and numerical optimization to minimize a function. The main idea behind gradient descent is to iteratively adjust the parameters of a model in the direction that reduces the value of a cost function.</p> <p>Hereâ€™s a step-by-step explanation of how gradient descent is done:</p> <ol> <li> <p>Initialize Parameters: Start with an initial set of parameters for the model. These parameters could be weights in a neural network or coefficients in a linear regression model.</p> </li> <li> <p>Calculate the Cost Function: Evaluate the cost function, which is a measure of how well the model is performing with the current set of parameters. The goal is to minimize this cost function.</p> </li> <li> <p>Calculate the Gradient: Compute the gradient of the cost function with respect to each parameter. The gradient represents the direction of the steepest increase in the cost function. Mathematically, it involves taking the partial derivative of the cost function with respect to each parameter.</p> </li> <li> <p>Update Parameters: Adjust the parameters in the opposite direction of the gradient. This is done to move towards the minimum of the cost function. The update is performed using the learning rate, which determines the size of the steps taken in the parameter space.</p> <blockquote> <p>New Parameter = Old Parameter âˆ’ Learning Rate Ã— Gradient</p> </blockquote> <p>The learning rate is a hyperparameter that needs to be carefully chosen. If itâ€™s too small, the algorithm may take a long time to converge, and if itâ€™s too large, it may overshoot the minimum.</p> </li> <li> <p>Repeat: Repeat steps 2-4 until convergence or a predetermined number of iterations. Convergence occurs when the parameters reach values where further adjustments donâ€™t significantly improve the cost function.</p> </li> </ol> <p>There are different variants of gradient descent, such as stochastic gradient descent (SGD) and mini-batch gradient descent, which involve using subsets of the training data for each iteration to reduce computational complexity. Additionally, more advanced optimization algorithms like Adam and RMSprop include adaptive learning rates to improve convergence speed. However, in this blog, I will implement the basic gradient descent.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/gradient-descent.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="Python"/><summary type="html"><![CDATA[Gradient Descent in Python with Jupyter Notebook]]></summary></entry><entry><title type="html">My Upcoming Project</title><link href="https://minsuan96.github.io/blog/2024/mahjong-rl/" rel="alternate" type="text/html" title="My Upcoming Project"/><published>2024-02-21T00:00:00+00:00</published><updated>2024-02-21T00:00:00+00:00</updated><id>https://minsuan96.github.io/blog/2024/mahjong-rl</id><content type="html" xml:base="https://minsuan96.github.io/blog/2024/mahjong-rl/"><![CDATA[<h4 id="hey-there-happy-chinese-new-year-">Hey there, Happy Chinese New Year! ğŸ‰</h4> <p>So, I just got back from this awesome Chinese New Year bash, and let me tell you, it was a blast! Loads of laughter, heaps of food, and of course, catching up with a bunch of cousins I havenâ€™t seen in ages. But you know whatâ€™s cool? A casual chat with one of my cousins sparked an idea thatâ€™s now turning into a pretty wild project.</p> <h4 id="the-mahjong-moment-">The Mahjong Moment ğŸ€„</h4> <p>Picture this: weâ€™re knee-deep in a <a href="https://en.wikipedia.org/wiki/Mahjong">mahjong</a> game, having a blast, when out of the blue, my cousin drops, â€œHey, why not make an AI that plays mahjong?â€ Lightbulb moment! So, from a simple family game, my new mission is to create a mahjong-playing AI. How cool is that?</p> <h4 id="reinforcement-learning-vibes-">Reinforcement Learning Vibes ğŸš€</h4> <p>Now, Iâ€™m no expert, but Iâ€™ve dabbled in reinforcement learning before â€“ you know, solving games like bipedal walker and acrobot using the <a href="https://gymnasium.farama.org/">gymnasium</a> library. But mahjong is a whole different ball game. Gymnasium is more of a solo playerâ€™s arena, and thatâ€™s when I stumbled upon <a href="https://pettingzoo.farama.org/">PettingZoo</a>. Itâ€™s like gymnasium but for the multiplayer crew.</p> <h4 id="enter-pettingzoo-ï¸">Enter PettingZoo ğŸ•¹ï¸</h4> <p>So, PettingZoo is my new playground. My goal? Cook up a custom environment for mahjong and get my agent geared up for some serious training. <a href="https://en.wikipedia.org/wiki/Multi-agent_reinforcement_learning">Multi-agent Reinforcement Learning</a> is the name of the game, and PettingZoo is my partner in crime. Exciting, right?</p> <h4 id="the-end-game-">The End Game ğŸ†</h4> <p>Now, hereâ€™s the kicker â€“ Iâ€™m not just looking to make an AI that can play mahjong; I want it to beat the seasoned pros. Yep, you heard that right. My mahjong AI is going to be the new reigning champ, taking down the best in the game. Ambitious? Heck yeah. Achievable? Time will tell.</p> <h4 id="stay-tuned-">Stay Tuned! ğŸ®</h4> <p>This journey from a family celebration to a full-blown reinforcement learning project is gonna be a rollercoaster. Stick around, because weâ€™re diving into the world of PettingZoo, shaping a mahjong battlefield, and aiming for the stars with an AI that can outsmart even the most seasoned players. Itâ€™s casual, itâ€™s fun, and itâ€™s about to get real interesting! ğŸš€âœ¨</p>]]></content><author><name></name></author><category term="mahjong"/><category term="reinforcement-learning"/><summary type="html"><![CDATA[Multi-agent Reinforcement Learning for Mahjong]]></summary></entry></feed>